x-airflow-common: &airflow-common
  build:
    context: .
    dockerfile: Dockerfile
    args:
      AIRFLOW_IMAGE: ${AIRFLOW_IMAGE:-apache/airflow:slim-3.1.7-python3.12}
  image: etl-airflow:3.1.7
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__LOAD_EXAMPLES: "False"
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER:?POSTGRES_USER is required}:${POSTGRES_PASSWORD:?POSTGRES_PASSWORD is required}@postgres:5432/${POSTGRES_DB:?POSTGRES_DB is required}
    AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_WEBSERVER_SECRET_KEY:?AIRFLOW_WEBSERVER_SECRET_KEY is required}
    AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY:?AIRFLOW_FERNET_KEY is required}
    DB_HOST: postgres
    DB_PORT: "5432"
    DB_NAME: ${POSTGRES_DB:?POSTGRES_DB is required}
    DB_USER: ${POSTGRES_USER:?POSTGRES_USER is required}
    DB_PASSWORD: ${POSTGRES_PASSWORD:?POSTGRES_PASSWORD is required}
    DB_TABLE: ${DB_TABLE:-posts}
    AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:?AWS_ACCESS_KEY_ID is required}
    AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:?AWS_SECRET_ACCESS_KEY is required}
    BUCKET_NAME: ${BUCKET_NAME:?BUCKET_NAME is required}
    REGION: ${REGION:?REGION is required}
    PYTHONPATH: /opt/airflow
  restart: unless-stopped
  depends_on:
    postgres:
      condition: service_healthy
  networks:
    - etl_net

services:
  postgres:
    image: postgres:16.6-alpine
    container_name: etl_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:?POSTGRES_USER is required}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?POSTGRES_PASSWORD is required}
      POSTGRES_DB: ${POSTGRES_DB:?POSTGRES_DB is required}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:?POSTGRES_USER is required} -d ${POSTGRES_DB:?POSTGRES_DB is required}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    restart: unless-stopped
    networks:
      - etl_net

  airflow-init:
    <<: *airflow-common
    container_name: airflow_init
    restart: "no"
    environment:
      <<: *airflow-common-env
      _AIRFLOW_WWW_USER_USERNAME: ${AIRFLOW_ADMIN_USERNAME:?AIRFLOW_ADMIN_USERNAME is required}
      _AIRFLOW_WWW_USER_PASSWORD: ${AIRFLOW_ADMIN_PASSWORD:?AIRFLOW_ADMIN_PASSWORD is required}
      _AIRFLOW_WWW_USER_FIRSTNAME: ${AIRFLOW_ADMIN_FIRSTNAME:-Airflow}
      _AIRFLOW_WWW_USER_LASTNAME: ${AIRFLOW_ADMIN_LASTNAME:-Admin}
      _AIRFLOW_WWW_USER_EMAIL: ${AIRFLOW_ADMIN_EMAIL:?AIRFLOW_ADMIN_EMAIL is required}
    command: >
      bash -c "airflow db migrate &&
               airflow users create
                 --username $${_AIRFLOW_WWW_USER_USERNAME}
                 --password $${_AIRFLOW_WWW_USER_PASSWORD}
                 --firstname $${_AIRFLOW_WWW_USER_FIRSTNAME}
                 --lastname $${_AIRFLOW_WWW_USER_LASTNAME}
                 --role Admin
                 --email $${_AIRFLOW_WWW_USER_EMAIL} || true"

  airflow-webserver:
    <<: *airflow-common
    container_name: airflow_webserver
    depends_on:
      postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    command: webserver
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8080/health')\""]
      interval: 20s
      timeout: 10s
      retries: 5
      start_period: 30s

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow_scheduler
    depends_on:
      postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    command: scheduler
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname $$HOSTNAME"]
      interval: 20s
      timeout: 10s
      retries: 5
      start_period: 30s

volumes:
  postgres_data:

networks:
  etl_net:
